# -*- coding: utf-8 -*-
"""segmentation-isci-2016_.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ll-G5N7a_Xzq7uJIR1S48NhzkeOQqKsK
"""

import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, Subset
from tqdm import tqdm
import albumentations as Alb
import os
import matplotlib.pyplot as plt
import cv2
import numpy as np
import torch

device= torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

class Load_ISIC_data(Dataset):
    def __init__(self, i_pth, m_pth, img_size, img_trfm=None):
        self.img_size = img_size
        self.m_pth = m_pth
        self.i_pth = i_pth
        self.trfm = img_trfm
        self.img_ids = [img_file[:-4] for img_file in os.listdir(i_pth) if img_file.endswith('.jpg')]


    def __len__(self):
        return len(self.img_ids)

    def __getitem__(self, idx):
        m_pth = os.path.join(self.m_pth, self.img_ids[idx] + '.png')
        i_pth = os.path.join(self.i_pth, self.img_ids[idx] + '.jpg')

        my_mask = cv2.imread(m_pth, cv2.IMREAD_GRAYSCALE)
        my_image = cv2.imread(i_pth, cv2.IMREAD_COLOR)

        my_image = cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)
        _, my_mask = cv2.threshold(my_mask, 127, 255, cv2.THRESH_BINARY)

        if self.trfm is not None:
            augmentations = self.trfm(image=my_image, mask=my_mask)
            my_mask = augmentations['mask']
            my_image = augmentations['image']

        my_mask = torch.from_numpy(my_mask).unsqueeze(0).float()
        my_mask[my_mask == 255.0] = 1.0
        my_image = torch.from_numpy(my_image).permute(2, 0, 1).float() / 255.


        return my_image, my_mask

class ImageTransforms:
    def __init__(self, size):
        self.size = size

    def __call__(self, image, mask):
        transform = Alb.Compose([
            Alb.Resize(height=self.size, width=self.size),
            Alb.HorizontalFlip(p=0.5),
            Alb.VerticalFlip(p=0.1)
        ])
        augmented = transform(image=image, mask=mask)
        return {'image': augmented['image'], 'mask': augmented['mask']}

train_img_path = '/kaggle/input/isic-segmentation-2016/ISIC 2016/train/'
train_mask_path = '/kaggle/input/isic-segmentation-2016/ISIC 2016/train_masks/'

test_img_path = '/kaggle/input/isic-segmentation-2016/ISIC 2016/test/'
test_mask_path = '/kaggle/input/isic-segmentation-2016/ISIC 2016/test_masks/'

size= 128
img_transforms = ImageTransforms(size=size)
train_dataset = Load_ISIC_data(i_pth=train_img_path, m_pth=train_mask_path, img_size=size, img_trfm=img_transforms)
test_dataset = Load_ISIC_data(i_pth=test_img_path, m_pth=test_mask_path, img_size=size, img_trfm=img_transforms)


train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,
                          num_workers=2, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

def plot(img, mask):
  img = img.permute(1, 2, 0).numpy()
  mask = mask.permute(1, 2, 0).squeeze().numpy()
  mask = cv2.resize(mask, (img.shape[1], img.shape[0]))
  mask = np.expand_dims(mask, axis=2)
  mask = np.repeat(mask, 3, axis=2)
  concatenated_img = np.concatenate((img, mask), axis=1)

  fig, ax = plt.subplots()
  ax.imshow(concatenated_img)
  ax.set_title('Image', loc='left')
  ax.set_title('Mask', loc='right')

  ax.set_xticks([])
  ax.set_yticks([])
  ax.set_xticklabels([])
  ax.set_yticklabels([])

  plt.show()

for i in range(5):
  img, mask = test_dataset[i]
  plot(img, mask)

img, mask = test_dataset[19]
print(img.shape, mask.shape)

# import MobileNetv2 for encoder
import torchvision.models as models
mobilenet = models.mobilenet_v2(pretrained=True)

class Segmentor(nn.Module):
    def __init__(self):
        super(Segmentor, self).__init__()

        # Load MobileNetV2 pretrained on ImageNet
        self.encoder = models.mobilenet_v2(pretrained=True).features

        # Decoder layers
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(1280, 512, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Conv2d(32, 1, kernel_size=1),
            #nn.Sigmoid()
        )

    def forward(self, x):
        # Encoder
        x = self.encoder(x)

        # Decoder
        x = self.decoder(x)

        return x

class SegmentationScore:
    @staticmethod
    def dice_score(y_pred, y_true):

        y_pred_flat = y_pred.view(-1)
        y_true_flat = y_true.view(-1)

        intersection = torch.sum(y_true_flat * y_pred_flat)
        union = torch.sum(y_true_flat) + torch.sum(y_pred_flat)

        dice = (2.0 * intersection) / (union)

        return dice

    @staticmethod
    def iou_score(y_pred, y_true):
        y_pred_flat = y_pred.view(-1)
        y_true_flat = y_true.view(-1)

        intersection = torch.sum(y_true_flat * y_pred_flat)
        union = torch.sum(y_true_flat) + torch.sum(y_pred_flat) - intersection

        iou = (intersection / union)

        return iou

class ModelTrainer:
    def __init__(self, model, criterion,dice_criterion,iou_criterion, optimizer, scaler, train_loader, test_loader):
        self.model = model
        self.criterion = criterion
        self.dice_criterion = dice_criterion
        self.iou_criterion = iou_criterion
        self.optimizer = optimizer
        self.scaler = scaler
        self.train_loader = train_loader
        self.test_loader = test_loader
        self.train_losses = []
        self.test_losses = []
        self.dice_scores = []
        self.iou_scores = []

    def train(self, total_epochs):
        for epoch in range(total_epochs):
            self.model.train()
            train_loss = 0.0
            test_loss = 0.0
            dice_score = 0.0
            iou_score = 0.0

            train_loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)

            for batch_idx, (images, masks) in train_loop:
                images, masks = images.to(device), masks.to(device)

                self.optimizer.zero_grad()

                with torch.cuda.amp.autocast():
                    outputs = self.model(images)
                    loss = self.criterion(outputs, masks)

                self.scaler.scale(loss).backward()
                self.scaler.step(self.optimizer)
                self.scaler.update()

                train_loss += loss.item()

            train_loss /= len(self.train_loader)
            self.train_losses.append(train_loss)

            self.model.eval()
            with torch.no_grad():
                for batch_idx, (images, masks) in enumerate(self.test_loader):
                    images, masks = images.to(device), masks.to(device)
                    #print(masks)
                    outputs = self.model(images)
                    #testing loss

                    loss = self.criterion(outputs, masks)
                    test_loss += loss.item()

                    m=nn.Sigmoid()
                    outputs1=m(outputs)
                    #print(outputs1)
                    outputs1[outputs1< 0.5] = 0
                    outputs1[outputs1>= 0.5] = 1

                    #dice score
                    score = self.dice_criterion(outputs1, masks)
                    dice_score += score.item()

                    #iou score
                    score = self.iou_criterion(outputs1, masks)
                    iou_score += score.item()

                test_loss /= len(self.test_loader)
                self.test_losses.append(test_loss)

                dice_score /= len(self.test_loader)
                self.dice_scores.append(dice_score)

                iou_score /= len(self.test_loader)
                self.iou_scores.append(iou_score)

            print(f"Epoch [{epoch+1}/{total_epochs}] || Train Loss: {train_loss:.4f} || Test/Val Loss: {test_loss:.4f}")
            print(f"Epoch [{epoch+1}/{total_epochs}] || Dice Score: {dice_score:.4f} || IoU Score: {iou_score:.4f}")

        return self.model

    def plot_losses(self):
        plt.figure()
        plt.plot(range(1, len(self.train_losses) + 1), self.train_losses, label='Training Loss')
        plt.plot(range(1, len(self.test_losses) + 1), self.test_losses, label='Test Loss')
        plt.xlabel('Epochs')
        plt.ylabel('Loss')
        plt.title('Training and Test Loss over Epochs')
        plt.legend()
        plt.show()

    def plot_dice_score(self):
        plt.figure()
        plt.plot(range(1, len(self.dice_scores) + 1), self.dice_scores, label='Dice Scores')
        plt.xlabel('Epochs')
        plt.ylabel('Score')
        plt.title('Dice Score over Epochs')
        plt.legend()
        plt.show()

    def plot_iou_score(self):
        plt.figure()
        plt.plot(range(1, len(self.iou_scores) + 1), self.iou_scores, label='IoU Score')
        plt.xlabel('Epochs')
        plt.ylabel('Score')
        plt.title('IoU Score over Epochs')
        plt.legend()
        plt.show()

#Off shelf learning
encoder_lr= 0
decoder_lr = 0.0001
Total_epochs= 20
seg = Segmentor().to(device)
criterion = nn.BCEWithLogitsLoss()
eval_criterion = SegmentationScore()
dice_criterion = eval_criterion.dice_score
iou_criterion = eval_criterion.iou_score
optimizer = optim.Adam([
    {'params': seg.encoder.parameters(), 'lr': encoder_lr},
    {'params': seg.decoder.parameters(), 'lr': decoder_lr}
])
scaler = torch.cuda.amp.GradScaler()

trainer = ModelTrainer(seg, criterion,dice_criterion,iou_criterion ,optimizer, scaler, train_loader, test_loader)
trained_model=trainer.train(Total_epochs)
trainer.plot_losses()
trainer.plot_dice_score()
trainer.plot_iou_score()

trained_model.eval()

sample_indices = np.random.choice(len(test_loader.dataset), 5, replace=False)

for idx in sample_indices:
    image, mask = test_loader.dataset[idx]

    #print(mask)

    image = image.unsqueeze(0)
    with torch.no_grad():
        outputs = trained_model(image.to(device))
        #print(outputs)
        m = nn.Sigmoid()
        outputs = m(outputs)
    outputs[outputs< 0.5] = 0
    outputs[outputs >= 0.5] = 1

    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    axes[0].imshow(image.squeeze().permute(1, 2, 0))
    axes[0].set_title('Input Image')
    axes[0].axis('off')
    axes[1].imshow(mask.squeeze(), cmap='gray')
    axes[1].set_title('Ground Truth Mask')
    axes[1].axis('off')
    axes[2].imshow(outputs.squeeze().cpu().numpy(), cmap='gray')
    axes[2].set_title('Predicted Mask')
    axes[2].axis('off')

    plt.show()

#Fine Tuning of Segmentation
encoder_lr= 0.001
decoder_lr = 0.001
Total_epochs= 20
seg = Segmentor().to(device)
criterion = nn.BCEWithLogitsLoss()
eval_criterion = SegmentationScore()
dice_criterion = eval_criterion.dice_score
iou_criterion = eval_criterion.iou_score
optimizer = optim.Adam([
    {'params': seg.encoder.parameters(), 'lr': encoder_lr},
    {'params': seg.decoder.parameters(), 'lr': decoder_lr}
])
scaler = torch.cuda.amp.GradScaler()

trainer = ModelTrainer(seg, criterion,dice_criterion,iou_criterion ,optimizer, scaler, train_loader, test_loader)
finetuned_model=trainer.train(Total_epochs)
trainer.plot_losses()
trainer.plot_dice_score()
trainer.plot_iou_score()

finetuned_model.eval()

sample_indices = np.random.choice(len(test_loader.dataset), 5, replace=False)

for idx in sample_indices:
    image, mask = test_loader.dataset[idx]

    image = image.unsqueeze(0)
    with torch.no_grad():
        outputs = trained_model(image.to(device))
        m = nn.Sigmoid()
        outputs = m(outputs)

    outputs[outputs< 0.5] = 0
    outputs[outputs >= 0.5] = 1

    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    axes[0].imshow(image.squeeze().permute(1, 2, 0))
    axes[0].set_title('Input Image')
    axes[0].axis('off')
    axes[1].imshow(mask.squeeze(), cmap='gray')
    axes[1].set_title('Ground Truth Mask')
    axes[1].axis('off')
    axes[2].imshow(outputs.squeeze().cpu().numpy(), cmap='gray')
    axes[2].set_title('Predicted Mask')
    axes[2].axis('off')

    plt.show()

